// RUN: xftn %S/../../../../examples/solvers/jacobi.F90 --openmp --stdout -t %S/tmp --cleanup --stages=flang,pre,ftn -v0 | FileCheck %s 
//CHECK:       builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", llvm.ident = "flang version 20.1.7 (https://github.com/llvm/llvm-project 6146a88f60492b520a36f8f8f3231e15f3cc6082)", llvm.target_triple = "x86_64-unknown-linux-gnu", omp.is_gpu = false, omp.is_target_device = false, omp.target_triples = [], omp.version = #omp<version <version = 11>>} {
//CHECK-NEXT:    omp.declare_reduction @add_reduction_f64 : f64 init {
//CHECK-NEXT:    ^0(%0 : f64):
//CHECK-NEXT:      %1 = arith.constant 0.000000e+00 : f64
//CHECK-NEXT:      omp.yield(%1 : f64)
//CHECK-NEXT:    } combiner {
//CHECK-NEXT:    ^1(%2 : f64, %3 : f64):
//CHECK-NEXT:      %4 = arith.addf %2, %3 fastmath<contract> : f64
//CHECK-NEXT:      omp.yield(%4 : f64)
//CHECK-NEXT:    }
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = f64, sym_name = "_QMjacobi_modECleft_value", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant}> ({
//CHECK-NEXT:      %0 = arith.constant 1.000000e+00 : f64
//CHECK-NEXT:      "llvm.return"(%0) : (f64) -> ()
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = i32, sym_name = "_QMjacobi_modECmax_iterations", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant}> ({
//CHECK-NEXT:      %1 = arith.constant 100000 : i32
//CHECK-NEXT:      "llvm.return"(%1) : (i32) -> ()
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = i32, sym_name = "_QMjacobi_modECreport_norm_period", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant}> ({
//CHECK-NEXT:      %2 = arith.constant 100 : i32
//CHECK-NEXT:      "llvm.return"(%2) : (i32) -> ()
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = f64, sym_name = "_QMjacobi_modECright_value", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant}> ({
//CHECK-NEXT:      %3 = arith.constant 1.000000e+01 : f64
//CHECK-NEXT:      "llvm.return"(%3) : (f64) -> ()
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    func.func @_QMjacobi_modPrun_solver(%4 : memref<i32> {fir.bindc_name = "nx"}, %5 : memref<i32> {fir.bindc_name = "ny"}, %6 : memref<f64> {fir.bindc_name = "convergence_accuracy"}) {
//CHECK-NEXT:      %7 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:      %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<f64>
//CHECK-NEXT:      %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:      %10 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<f64>
//CHECK-NEXT:      %11 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<f64>
//CHECK-NEXT:      %12 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<memref<?x?xf64>>
//CHECK-NEXT:      %13 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<memref<?x?xf64>>
//CHECK-NEXT:      %14 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<memref<?x?xf64>>
//CHECK-NEXT:      %15 = arith.constant 6 : i32
//CHECK-NEXT:      %16 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:      %17 = "llvm.getelementptr"(%16) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:      %18 = arith.constant 23 : i32
//CHECK-NEXT:      %19 = func.call @_FortranAioBeginExternalListOutput(%15, %17, %18) : (i32, !llvm.ptr, i32) -> !llvm.ptr
//CHECK-NEXT:      %20 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:      %21 = "llvm.getelementptr"(%20) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:      %22 = arith.constant 17 : index
//CHECK-NEXT:      %23 = arith.index_cast %22 : index to i64
//CHECK-NEXT:      %24 = func.call @_FortranAioOutputAscii(%19, %21, %23) : (!llvm.ptr, !llvm.ptr, i64) -> i1
//CHECK-NEXT:      %25 = memref.load %4[] : memref<i32>
//CHECK-NEXT:      %26 = func.call @_FortranAioOutputInteger32(%19, %25) : (!llvm.ptr, i32) -> i1
//CHECK-NEXT:      %27 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:      %28 = "llvm.getelementptr"(%27) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:      %29 = arith.constant 17 : index
//CHECK-NEXT:      %30 = arith.index_cast %29 : index to i64
//CHECK-NEXT:      %31 = func.call @_FortranAioOutputAscii(%19, %28, %30) : (!llvm.ptr, !llvm.ptr, i64) -> i1
//CHECK-NEXT:      %32 = memref.load %5[] : memref<i32>
//CHECK-NEXT:      %33 = func.call @_FortranAioOutputInteger32(%19, %32) : (!llvm.ptr, i32) -> i1
//CHECK-NEXT:      %34 = func.call @_FortranAioEndIoStatement(%19) : (!llvm.ptr) -> i32
//CHECK-NEXT:      %35 = memref.load %5[] : memref<i32>
//CHECK-NEXT:      %36 = arith.constant 1 : i32
//CHECK-NEXT:      %37 = arith.addi %35, %36 : i32
//CHECK-NEXT:      %38 = arith.index_cast %37 : i32 to index
//CHECK-NEXT:      %39 = arith.constant 1 : index
//CHECK-NEXT:      %40 = arith.addi %38, %39 : index
//CHECK-NEXT:      %41 = memref.load %4[] : memref<i32>
//CHECK-NEXT:      %42 = arith.constant 1 : i32
//CHECK-NEXT:      %43 = arith.addi %41, %42 : i32
//CHECK-NEXT:      %44 = arith.index_cast %43 : i32 to index
//CHECK-NEXT:      %45 = arith.constant 1 : index
//CHECK-NEXT:      %46 = arith.addi %44, %45 : index
//CHECK-NEXT:      %47 = memref.alloc(%46, %40) : memref<?x?xf64>
//CHECK-NEXT:      memref.store %47, %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      %48 = memref.load %5[] : memref<i32>
//CHECK-NEXT:      %49 = arith.constant 1 : i32
//CHECK-NEXT:      %50 = arith.addi %48, %49 : i32
//CHECK-NEXT:      %51 = arith.index_cast %50 : i32 to index
//CHECK-NEXT:      %52 = arith.constant 1 : index
//CHECK-NEXT:      %53 = arith.addi %51, %52 : index
//CHECK-NEXT:      %54 = memref.load %4[] : memref<i32>
//CHECK-NEXT:      %55 = arith.constant 1 : i32
//CHECK-NEXT:      %56 = arith.addi %54, %55 : i32
//CHECK-NEXT:      %57 = arith.index_cast %56 : i32 to index
//CHECK-NEXT:      %58 = arith.constant 1 : index
//CHECK-NEXT:      %59 = arith.addi %57, %58 : index
//CHECK-NEXT:      %60 = memref.alloc(%59, %53) : memref<?x?xf64>
//CHECK-NEXT:      memref.store %60, %14[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      %61 = arith.constant 0.000000e+00 : f64
//CHECK-NEXT:      memref.store %61, %8[] : memref<f64>
//CHECK-NEXT:      %62 = arith.constant 0.000000e+00 : f64
//CHECK-NEXT:      memref.store %62, %11[] : memref<f64>
//CHECK-NEXT:      "memref.alloca_scope"() ({
//CHECK-NEXT:        %63 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:        %64 = "memref.cast"(%63) : (memref<?x?xf64>) -> memref<?x?xf64>
//CHECK-NEXT:        %65 = memref.load %14[] : memref<memref<?x?xf64>>
//CHECK-NEXT:        %66 = "memref.cast"(%65) : (memref<?x?xf64>) -> memref<?x?xf64>
//CHECK-NEXT:        func.call @_QMjacobi_modPinitialise_values(%64, %66, %4, %5) : (memref<?x?xf64>, memref<?x?xf64>, memref<i32>, memref<i32>) -> ()
//CHECK-NEXT:        "memref.alloca_scope.return"() : () -> ()
//CHECK-NEXT:      }) : () -> ()
//CHECK-NEXT:      "omp.parallel"() <{operandSegmentSizes = array<i32: 0, 0, 0, 0, 0, 0>}> ({
//CHECK-NEXT:        %67 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        %68 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        %69 = "memref.extract_aligned_pointer_as_index"(%8) : (memref<f64>) -> index
//CHECK-NEXT:        %70 = arith.index_cast %69 : index to i64
//CHECK-NEXT:        %71 = "llvm.inttoptr"(%70) : (i64) -> !llvm.ptr
//CHECK-NEXT:        %72 = arith.constant 1 : i32
//CHECK-NEXT:        %73 = arith.constant 1 : i32
//CHECK-NEXT:        %74 = memref.load %4[] : memref<i32>
//CHECK-NEXT:        %75 = memref.load %5[] : memref<i32>
//CHECK-NEXT:        %76 = arith.constant 1 : i32
//CHECK-NEXT:        %77 = arith.constant 1 : i32
//CHECK-NEXT:        "omp.wsloop"(%71) <{reduction_byref = array<i1: false>, reduction_syms = [@add_reduction_f64], operandSegmentSizes = array<i32: 0, 0, 0, 0, 0, 1, 0>}> ({
//CHECK-NEXT:        ^0(%78 : !llvm.ptr):
//CHECK-NEXT:          "omp.loop_nest"(%72, %73, %74, %75, %76, %77) <{loop_inclusive}> ({
//CHECK-NEXT:          ^1(%79 : i32, %80 : i32):
//CHECK-NEXT:            memref.store %79, %67[] : memref<i32>
//CHECK-NEXT:            memref.store %80, %68[] : memref<i32>
//CHECK-NEXT:            %81 = "llvm.load"(%78) : (!llvm.ptr) -> f64
//CHECK-NEXT:            %82 = memref.load %68[] : memref<i32>
//CHECK-NEXT:            %83 = arith.extui %82 : i32 to i64
//CHECK-NEXT:            %84 = arith.index_cast %83 : i64 to index
//CHECK-NEXT:            %85 = memref.load %67[] : memref<i32>
//CHECK-NEXT:            %86 = arith.extui %85 : i32 to i64
//CHECK-NEXT:            %87 = arith.index_cast %86 : i64 to index
//CHECK-NEXT:            %88 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %89 = memref.load %88[%87, %84] : memref<?x?xf64>
//CHECK-NEXT:            %90 = arith.constant 4.000000e+00 : f64
//CHECK-NEXT:            %91 = arith.mulf %89, %90 fastmath<contract> : f64
//CHECK-NEXT:            %92 = memref.load %68[] : memref<i32>
//CHECK-NEXT:            %93 = arith.constant 1 : i32
//CHECK-NEXT:            %94 = arith.subi %92, %93 : i32
//CHECK-NEXT:            %95 = arith.extui %94 : i32 to i64
//CHECK-NEXT:            %96 = arith.index_cast %95 : i64 to index
//CHECK-NEXT:            %97 = memref.load %67[] : memref<i32>
//CHECK-NEXT:            %98 = arith.extui %97 : i32 to i64
//CHECK-NEXT:            %99 = arith.index_cast %98 : i64 to index
//CHECK-NEXT:            %100 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %101 = memref.load %100[%99, %96] : memref<?x?xf64>
//CHECK-NEXT:            %102 = arith.subf %91, %101 fastmath<contract> : f64
//CHECK-NEXT:            %103 = memref.load %68[] : memref<i32>
//CHECK-NEXT:            %104 = arith.constant 1 : i32
//CHECK-NEXT:            %105 = arith.addi %103, %104 : i32
//CHECK-NEXT:            %106 = arith.extui %105 : i32 to i64
//CHECK-NEXT:            %107 = arith.index_cast %106 : i64 to index
//CHECK-NEXT:            %108 = memref.load %67[] : memref<i32>
//CHECK-NEXT:            %109 = arith.extui %108 : i32 to i64
//CHECK-NEXT:            %110 = arith.index_cast %109 : i64 to index
//CHECK-NEXT:            %111 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %112 = memref.load %111[%110, %107] : memref<?x?xf64>
//CHECK-NEXT:            %113 = arith.subf %102, %112 fastmath<contract> : f64
//CHECK-NEXT:            %114 = memref.load %68[] : memref<i32>
//CHECK-NEXT:            %115 = arith.extui %114 : i32 to i64
//CHECK-NEXT:            %116 = arith.index_cast %115 : i64 to index
//CHECK-NEXT:            %117 = memref.load %67[] : memref<i32>
//CHECK-NEXT:            %118 = arith.constant 1 : i32
//CHECK-NEXT:            %119 = arith.subi %117, %118 : i32
//CHECK-NEXT:            %120 = arith.extui %119 : i32 to i64
//CHECK-NEXT:            %121 = arith.index_cast %120 : i64 to index
//CHECK-NEXT:            %122 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %123 = memref.load %122[%121, %116] : memref<?x?xf64>
//CHECK-NEXT:            %124 = arith.subf %113, %123 fastmath<contract> : f64
//CHECK-NEXT:            %125 = memref.load %68[] : memref<i32>
//CHECK-NEXT:            %126 = arith.extui %125 : i32 to i64
//CHECK-NEXT:            %127 = arith.index_cast %126 : i64 to index
//CHECK-NEXT:            %128 = memref.load %67[] : memref<i32>
//CHECK-NEXT:            %129 = arith.constant 1 : i32
//CHECK-NEXT:            %130 = arith.addi %128, %129 : i32
//CHECK-NEXT:            %131 = arith.extui %130 : i32 to i64
//CHECK-NEXT:            %132 = arith.index_cast %131 : i64 to index
//CHECK-NEXT:            %133 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %134 = memref.load %133[%132, %127] : memref<?x?xf64>
//CHECK-NEXT:            %135 = arith.subf %124, %134 fastmath<contract> : f64
//CHECK-NEXT:            %136 = arith.constant 2 : i32
//CHECK-NEXT:            %137 = math.fpowi %135, %136 {fastmath = #arith.fastmath<contract>} : f64, i32
//CHECK-NEXT:            %138 = arith.addf %81, %137 fastmath<contract> : f64
//CHECK-NEXT:            "llvm.store"(%138, %78) <{ordering = 0 : i64}> : (f64, !llvm.ptr) -> ()
//CHECK-NEXT:            omp.yield
//CHECK-NEXT:          }) : (i32, i32, i32, i32, i32, i32) -> ()
//CHECK-NEXT:        }) : (!llvm.ptr) -> ()
//CHECK-NEXT:        "omp.terminator"() : () -> ()
//CHECK-NEXT:      }) : () -> ()
//CHECK-NEXT:      %139 = memref.load %8[] : memref<f64>
//CHECK-NEXT:      %140 = math.sqrt %139 fastmath<contract> : f64
//CHECK-NEXT:      memref.store %140, %8[] : memref<f64>
//CHECK-NEXT:      %141 = arith.constant 0 : i32
//CHECK-NEXT:      %142 = arith.constant 100001 : i32
//CHECK-NEXT:      memref.store %142, %7[] : memref<i32>
//CHECK-NEXT:      memref.store %141, %9[] : memref<i32>
//CHECK-NEXT:      cf.br ^2
//CHECK-NEXT:    ^2:
//CHECK-NEXT:      %143 = memref.load %7[] : memref<i32>
//CHECK-NEXT:      %144 = arith.constant 0 : i32
//CHECK-NEXT:      %145 = arith.cmpi sgt, %143, %144 : i32
//CHECK-NEXT:      cf.cond_br %145, ^3, ^4
//CHECK-NEXT:    ^3:
//CHECK-NEXT:      %146 = arith.constant 0.000000e+00 : f64
//CHECK-NEXT:      memref.store %146, %11[] : memref<f64>
//CHECK-NEXT:      "omp.parallel"() <{operandSegmentSizes = array<i32: 0, 0, 0, 0, 0, 0>}> ({
//CHECK-NEXT:        %147 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        %148 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        %149 = "memref.extract_aligned_pointer_as_index"(%11) : (memref<f64>) -> index
//CHECK-NEXT:        %150 = arith.index_cast %149 : index to i64
//CHECK-NEXT:        %151 = "llvm.inttoptr"(%150) : (i64) -> !llvm.ptr
//CHECK-NEXT:        %152 = arith.constant 1 : i32
//CHECK-NEXT:        %153 = arith.constant 1 : i32
//CHECK-NEXT:        %154 = memref.load %4[] : memref<i32>
//CHECK-NEXT:        %155 = memref.load %5[] : memref<i32>
//CHECK-NEXT:        %156 = arith.constant 1 : i32
//CHECK-NEXT:        %157 = arith.constant 1 : i32
//CHECK-NEXT:        "omp.wsloop"(%151) <{reduction_byref = array<i1: false>, reduction_syms = [@add_reduction_f64], operandSegmentSizes = array<i32: 0, 0, 0, 0, 0, 1, 0>}> ({
//CHECK-NEXT:        ^5(%158 : !llvm.ptr):
//CHECK-NEXT:          "omp.loop_nest"(%152, %153, %154, %155, %156, %157) <{loop_inclusive}> ({
//CHECK-NEXT:          ^6(%159 : i32, %160 : i32):
//CHECK-NEXT:            memref.store %159, %147[] : memref<i32>
//CHECK-NEXT:            memref.store %160, %148[] : memref<i32>
//CHECK-NEXT:            %161 = "llvm.load"(%158) : (!llvm.ptr) -> f64
//CHECK-NEXT:            %162 = memref.load %148[] : memref<i32>
//CHECK-NEXT:            %163 = arith.extui %162 : i32 to i64
//CHECK-NEXT:            %164 = arith.index_cast %163 : i64 to index
//CHECK-NEXT:            %165 = memref.load %147[] : memref<i32>
//CHECK-NEXT:            %166 = arith.extui %165 : i32 to i64
//CHECK-NEXT:            %167 = arith.index_cast %166 : i64 to index
//CHECK-NEXT:            %168 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %169 = memref.load %168[%167, %164] : memref<?x?xf64>
//CHECK-NEXT:            %170 = arith.constant 4.000000e+00 : f64
//CHECK-NEXT:            %171 = arith.mulf %169, %170 fastmath<contract> : f64
//CHECK-NEXT:            %172 = memref.load %148[] : memref<i32>
//CHECK-NEXT:            %173 = arith.constant 1 : i32
//CHECK-NEXT:            %174 = arith.subi %172, %173 : i32
//CHECK-NEXT:            %175 = arith.extui %174 : i32 to i64
//CHECK-NEXT:            %176 = arith.index_cast %175 : i64 to index
//CHECK-NEXT:            %177 = memref.load %147[] : memref<i32>
//CHECK-NEXT:            %178 = arith.extui %177 : i32 to i64
//CHECK-NEXT:            %179 = arith.index_cast %178 : i64 to index
//CHECK-NEXT:            %180 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %181 = memref.load %180[%179, %176] : memref<?x?xf64>
//CHECK-NEXT:            %182 = arith.subf %171, %181 fastmath<contract> : f64
//CHECK-NEXT:            %183 = memref.load %148[] : memref<i32>
//CHECK-NEXT:            %184 = arith.constant 1 : i32
//CHECK-NEXT:            %185 = arith.addi %183, %184 : i32
//CHECK-NEXT:            %186 = arith.extui %185 : i32 to i64
//CHECK-NEXT:            %187 = arith.index_cast %186 : i64 to index
//CHECK-NEXT:            %188 = memref.load %147[] : memref<i32>
//CHECK-NEXT:            %189 = arith.extui %188 : i32 to i64
//CHECK-NEXT:            %190 = arith.index_cast %189 : i64 to index
//CHECK-NEXT:            %191 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %192 = memref.load %191[%190, %187] : memref<?x?xf64>
//CHECK-NEXT:            %193 = arith.subf %182, %192 fastmath<contract> : f64
//CHECK-NEXT:            %194 = memref.load %148[] : memref<i32>
//CHECK-NEXT:            %195 = arith.extui %194 : i32 to i64
//CHECK-NEXT:            %196 = arith.index_cast %195 : i64 to index
//CHECK-NEXT:            %197 = memref.load %147[] : memref<i32>
//CHECK-NEXT:            %198 = arith.constant 1 : i32
//CHECK-NEXT:            %199 = arith.subi %197, %198 : i32
//CHECK-NEXT:            %200 = arith.extui %199 : i32 to i64
//CHECK-NEXT:            %201 = arith.index_cast %200 : i64 to index
//CHECK-NEXT:            %202 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %203 = memref.load %202[%201, %196] : memref<?x?xf64>
//CHECK-NEXT:            %204 = arith.subf %193, %203 fastmath<contract> : f64
//CHECK-NEXT:            %205 = memref.load %148[] : memref<i32>
//CHECK-NEXT:            %206 = arith.extui %205 : i32 to i64
//CHECK-NEXT:            %207 = arith.index_cast %206 : i64 to index
//CHECK-NEXT:            %208 = memref.load %147[] : memref<i32>
//CHECK-NEXT:            %209 = arith.constant 1 : i32
//CHECK-NEXT:            %210 = arith.addi %208, %209 : i32
//CHECK-NEXT:            %211 = arith.extui %210 : i32 to i64
//CHECK-NEXT:            %212 = arith.index_cast %211 : i64 to index
//CHECK-NEXT:            %213 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %214 = memref.load %213[%212, %207] : memref<?x?xf64>
//CHECK-NEXT:            %215 = arith.subf %204, %214 fastmath<contract> : f64
//CHECK-NEXT:            %216 = arith.constant 2 : i32
//CHECK-NEXT:            %217 = math.fpowi %215, %216 {fastmath = #arith.fastmath<contract>} : f64, i32
//CHECK-NEXT:            %218 = arith.addf %161, %217 fastmath<contract> : f64
//CHECK-NEXT:            "llvm.store"(%218, %158) <{ordering = 0 : i64}> : (f64, !llvm.ptr) -> ()
//CHECK-NEXT:            omp.yield
//CHECK-NEXT:          }) : (i32, i32, i32, i32, i32, i32) -> ()
//CHECK-NEXT:        }) : (!llvm.ptr) -> ()
//CHECK-NEXT:        "omp.terminator"() : () -> ()
//CHECK-NEXT:      }) : () -> ()
//CHECK-NEXT:      %219 = memref.load %11[] : memref<f64>
//CHECK-NEXT:      %220 = math.sqrt %219 fastmath<contract> : f64
//CHECK-NEXT:      %221 = memref.load %8[] : memref<f64>
//CHECK-NEXT:      %222 = arith.divf %220, %221 fastmath<contract> : f64
//CHECK-NEXT:      memref.store %222, %10[] : memref<f64>
//CHECK-NEXT:      %223 = memref.load %10[] : memref<f64>
//CHECK-NEXT:      %224 = memref.load %6[] : memref<f64>
//CHECK-NEXT:      %225 = arith.cmpf olt, %223, %224 : f64
//CHECK-NEXT:      cf.cond_br %225, ^4, ^7
//CHECK-NEXT:    ^7:
//CHECK-NEXT:      "omp.parallel"() <{operandSegmentSizes = array<i32: 0, 0, 0, 0, 0, 0>}> ({
//CHECK-NEXT:        %226 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        %227 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        %228 = arith.constant 1 : i32
//CHECK-NEXT:        %229 = arith.constant 1 : i32
//CHECK-NEXT:        %230 = memref.load %4[] : memref<i32>
//CHECK-NEXT:        %231 = memref.load %5[] : memref<i32>
//CHECK-NEXT:        %232 = arith.constant 1 : i32
//CHECK-NEXT:        %233 = arith.constant 1 : i32
//CHECK-NEXT:        "omp.wsloop"() <{operandSegmentSizes = array<i32: 0, 0, 0, 0, 0, 0, 0>}> ({
//CHECK-NEXT:          "omp.loop_nest"(%228, %229, %230, %231, %232, %233) <{loop_inclusive}> ({
//CHECK-NEXT:          ^8(%234 : i32, %235 : i32):
//CHECK-NEXT:            memref.store %234, %226[] : memref<i32>
//CHECK-NEXT:            memref.store %235, %227[] : memref<i32>
//CHECK-NEXT:            %236 = arith.constant 2.500000e-01 : f64
//CHECK-NEXT:            %237 = memref.load %227[] : memref<i32>
//CHECK-NEXT:            %238 = arith.constant 1 : i32
//CHECK-NEXT:            %239 = arith.subi %237, %238 : i32
//CHECK-NEXT:            %240 = arith.extui %239 : i32 to i64
//CHECK-NEXT:            %241 = arith.index_cast %240 : i64 to index
//CHECK-NEXT:            %242 = memref.load %226[] : memref<i32>
//CHECK-NEXT:            %243 = arith.extui %242 : i32 to i64
//CHECK-NEXT:            %244 = arith.index_cast %243 : i64 to index
//CHECK-NEXT:            %245 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %246 = memref.load %245[%244, %241] : memref<?x?xf64>
//CHECK-NEXT:            %247 = memref.load %227[] : memref<i32>
//CHECK-NEXT:            %248 = arith.constant 1 : i32
//CHECK-NEXT:            %249 = arith.addi %247, %248 : i32
//CHECK-NEXT:            %250 = arith.extui %249 : i32 to i64
//CHECK-NEXT:            %251 = arith.index_cast %250 : i64 to index
//CHECK-NEXT:            %252 = memref.load %226[] : memref<i32>
//CHECK-NEXT:            %253 = arith.extui %252 : i32 to i64
//CHECK-NEXT:            %254 = arith.index_cast %253 : i64 to index
//CHECK-NEXT:            %255 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %256 = memref.load %255[%254, %251] : memref<?x?xf64>
//CHECK-NEXT:            %257 = arith.addf %246, %256 fastmath<contract> : f64
//CHECK-NEXT:            %258 = memref.load %227[] : memref<i32>
//CHECK-NEXT:            %259 = arith.extui %258 : i32 to i64
//CHECK-NEXT:            %260 = arith.index_cast %259 : i64 to index
//CHECK-NEXT:            %261 = memref.load %226[] : memref<i32>
//CHECK-NEXT:            %262 = arith.constant 1 : i32
//CHECK-NEXT:            %263 = arith.subi %261, %262 : i32
//CHECK-NEXT:            %264 = arith.extui %263 : i32 to i64
//CHECK-NEXT:            %265 = arith.index_cast %264 : i64 to index
//CHECK-NEXT:            %266 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %267 = memref.load %266[%265, %260] : memref<?x?xf64>
//CHECK-NEXT:            %268 = arith.addf %257, %267 fastmath<contract> : f64
//CHECK-NEXT:            %269 = memref.load %227[] : memref<i32>
//CHECK-NEXT:            %270 = arith.extui %269 : i32 to i64
//CHECK-NEXT:            %271 = arith.index_cast %270 : i64 to index
//CHECK-NEXT:            %272 = memref.load %226[] : memref<i32>
//CHECK-NEXT:            %273 = arith.constant 1 : i32
//CHECK-NEXT:            %274 = arith.addi %272, %273 : i32
//CHECK-NEXT:            %275 = arith.extui %274 : i32 to i64
//CHECK-NEXT:            %276 = arith.index_cast %275 : i64 to index
//CHECK-NEXT:            %277 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            %278 = memref.load %277[%276, %271] : memref<?x?xf64>
//CHECK-NEXT:            %279 = arith.addf %268, %278 fastmath<contract> : f64
//CHECK-NEXT:            %280 = arith.mulf %236, %279 fastmath<contract> : f64
//CHECK-NEXT:            %281 = memref.load %227[] : memref<i32>
//CHECK-NEXT:            %282 = arith.extui %281 : i32 to i64
//CHECK-NEXT:            %283 = arith.index_cast %282 : i64 to index
//CHECK-NEXT:            %284 = memref.load %226[] : memref<i32>
//CHECK-NEXT:            %285 = arith.extui %284 : i32 to i64
//CHECK-NEXT:            %286 = arith.index_cast %285 : i64 to index
//CHECK-NEXT:            %287 = memref.load %14[] : memref<memref<?x?xf64>>
//CHECK-NEXT:            memref.store %280, %287[%286, %283] : memref<?x?xf64>
//CHECK-NEXT:            omp.yield
//CHECK-NEXT:          }) : (i32, i32, i32, i32, i32, i32) -> ()
//CHECK-NEXT:        }) : () -> ()
//CHECK-NEXT:        "omp.terminator"() : () -> ()
//CHECK-NEXT:      }) : () -> ()
//CHECK-NEXT:      %288 = memref.load %14[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      memref.store %288, %12[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      %289 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      memref.store %289, %14[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      %290 = memref.load %12[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      memref.store %290, %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      %291 = memref.load %9[] : memref<i32>
//CHECK-NEXT:      %292 = arith.constant 100 : i32
//CHECK-NEXT:      %293 = arith.remsi %291, %292 : i32
//CHECK-NEXT:      %294 = arith.constant 0 : i32
//CHECK-NEXT:      %295 = arith.cmpi eq, %293, %294 : i32
//CHECK-NEXT:      scf.if %295 {
//CHECK-NEXT:        %296 = arith.constant 6 : i32
//CHECK-NEXT:        %297 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:        %298 = "llvm.getelementptr"(%297) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:        %299 = arith.constant 75 : i32
//CHECK-NEXT:        %300 = func.call @_FortranAioBeginExternalListOutput(%296, %298, %299) : (i32, !llvm.ptr, i32) -> !llvm.ptr
//CHECK-NEXT:        %301 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:        %302 = "llvm.getelementptr"(%301) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:        %303 = arith.constant 10 : index
//CHECK-NEXT:        %304 = arith.index_cast %303 : index to i64
//CHECK-NEXT:        %305 = func.call @_FortranAioOutputAscii(%300, %302, %304) : (!llvm.ptr, !llvm.ptr, i64) -> i1
//CHECK-NEXT:        %306 = memref.load %9[] : memref<i32>
//CHECK-NEXT:        %307 = func.call @_FortranAioOutputInteger32(%300, %306) : (!llvm.ptr, i32) -> i1
//CHECK-NEXT:        %308 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:        %309 = "llvm.getelementptr"(%308) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:        %310 = arith.constant 15 : index
//CHECK-NEXT:        %311 = arith.index_cast %310 : index to i64
//CHECK-NEXT:        %312 = func.call @_FortranAioOutputAscii(%300, %309, %311) : (!llvm.ptr, !llvm.ptr, i64) -> i1
//CHECK-NEXT:        %313 = memref.load %10[] : memref<f64>
//CHECK-NEXT:        %314 = func.call @_FortranAioOutputReal64(%300, %313) : (!llvm.ptr, f64) -> i1
//CHECK-NEXT:        %315 = func.call @_FortranAioEndIoStatement(%300) : (!llvm.ptr) -> i32
//CHECK-NEXT:      } else {
//CHECK-NEXT:      }
//CHECK-NEXT:      %316 = memref.load %7[] : memref<i32>
//CHECK-NEXT:      %317 = arith.constant 1 : i32
//CHECK-NEXT:      %318 = arith.subi %316, %317 : i32
//CHECK-NEXT:      memref.store %318, %7[] : memref<i32>
//CHECK-NEXT:      %319 = memref.load %9[] : memref<i32>
//CHECK-NEXT:      %320 = arith.constant 1 : i32
//CHECK-NEXT:      %321 = arith.addi %319, %320 : i32
//CHECK-NEXT:      memref.store %321, %9[] : memref<i32>
//CHECK-NEXT:      cf.br ^2
//CHECK-NEXT:    ^4:
//CHECK-NEXT:      %322 = arith.constant 6 : i32
//CHECK-NEXT:      %323 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:      %324 = "llvm.getelementptr"(%323) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:      %325 = arith.constant 77 : i32
//CHECK-NEXT:      %326 = func.call @_FortranAioBeginExternalListOutput(%322, %324, %325) : (i32, !llvm.ptr, i32) -> !llvm.ptr
//CHECK-NEXT:      %327 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:      %328 = "llvm.getelementptr"(%327) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:      %329 = arith.constant 14 : index
//CHECK-NEXT:      %330 = arith.index_cast %329 : index to i64
//CHECK-NEXT:      %331 = func.call @_FortranAioOutputAscii(%326, %328, %330) : (!llvm.ptr, !llvm.ptr, i64) -> i1
//CHECK-NEXT:      %332 = memref.load %9[] : memref<i32>
//CHECK-NEXT:      %333 = func.call @_FortranAioOutputInteger32(%326, %332) : (!llvm.ptr, i32) -> i1
//CHECK-NEXT:      %334 = "llvm.mlir.addressof"() <{global_name = @{{.*}}}> : () -> !llvm.ptr
//CHECK-NEXT:      %335 = "llvm.getelementptr"(%334) <{rawConstantIndices = array<i32: 0, 0>, elem_type = !llvm.array<1 x i8>}> : (!llvm.ptr) -> !llvm.ptr
//CHECK-NEXT:      %336 = arith.constant 27 : index
//CHECK-NEXT:      %337 = arith.index_cast %336 : index to i64
//CHECK-NEXT:      %338 = func.call @_FortranAioOutputAscii(%326, %335, %337) : (!llvm.ptr, !llvm.ptr, i64) -> i1
//CHECK-NEXT:      %339 = memref.load %10[] : memref<f64>
//CHECK-NEXT:      %340 = func.call @_FortranAioOutputReal64(%326, %339) : (!llvm.ptr, f64) -> i1
//CHECK-NEXT:      %341 = func.call @_FortranAioEndIoStatement(%326) : (!llvm.ptr) -> i32
//CHECK-NEXT:      %342 = memref.load %13[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      memref.dealloc %342 : memref<?x?xf64>
//CHECK-NEXT:      %343 = memref.load %14[] : memref<memref<?x?xf64>>
//CHECK-NEXT:      memref.dealloc %343 : memref<?x?xf64>
//CHECK-NEXT:      func.return
//CHECK-NEXT:    }
//CHECK-NEXT:    func.func @_QMjacobi_modPinitialise_values(%4 : memref<?x?xf64> {fir.bindc_name = "u_k"}, %5 : memref<?x?xf64> {fir.bindc_name = "u_kp1"}, %6 : memref<i32> {fir.bindc_name = "nx"}, %7 : memref<i32> {fir.bindc_name = "ny"}) {
//CHECK-NEXT:      %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:      %9 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:      %10 = arith.constant 0 : i64
//CHECK-NEXT:      %11 = arith.index_cast %10 : i64 to index
//CHECK-NEXT:      %12 = arith.constant 0 : i32
//CHECK-NEXT:      %13 = arith.index_cast %12 : i32 to index
//CHECK-NEXT:      %14 = memref.load %6[] : memref<i32>
//CHECK-NEXT:      %15 = arith.constant 1 : i32
//CHECK-NEXT:      %16 = arith.addi %14, %15 : i32
//CHECK-NEXT:      %17 = arith.index_cast %16 : i32 to index
//CHECK-NEXT:      %18 = arith.constant 1 : index
//CHECK-NEXT:      %19 = arith.index_cast %13 : index to i32
//CHECK-NEXT:      %20 = arith.addi %17, %18 : index
//CHECK-NEXT:      %21 = arith.constant 0.000000e+00 : f64
//CHECK-NEXT:      %22 = scf.for %23 = %13 to %20 step %18 iter_args(%24 = %19) -> (i32) {
//CHECK-NEXT:        memref.store %24, %8[] : memref<i32>
//CHECK-NEXT:        %25 = arith.index_cast %15 : i32 to index
//CHECK-NEXT:        %26 = memref.load %7[] : memref<i32>
//CHECK-NEXT:        %27 = arith.index_cast %26 : i32 to index
//CHECK-NEXT:        %28 = arith.index_cast %25 : index to i32
//CHECK-NEXT:        %29 = arith.addi %27, %18 : index
//CHECK-NEXT:        %30 = scf.for %31 = %25 to %29 step %18 iter_args(%32 = %28) -> (i32) {
//CHECK-NEXT:          memref.store %32, %9[] : memref<i32>
//CHECK-NEXT:          %33 = memref.load %9[] : memref<i32>
//CHECK-NEXT:          %34 = arith.extui %33 : i32 to i64
//CHECK-NEXT:          %35 = arith.index_cast %34 : i64 to index
//CHECK-NEXT:          %36 = arith.subi %35, %11 : index
//CHECK-NEXT:          %37 = memref.load %8[] : memref<i32>
//CHECK-NEXT:          %38 = arith.extui %37 : i32 to i64
//CHECK-NEXT:          %39 = arith.index_cast %38 : i64 to index
//CHECK-NEXT:          %40 = arith.subi %39, %11 : index
//CHECK-NEXT:          memref.store %21, %4[%40, %36] : memref<?x?xf64>
//CHECK-NEXT:          %41 = memref.load %9[] : memref<i32>
//CHECK-NEXT:          %42 = arith.index_cast %18 : index to i32
//CHECK-NEXT:          %43 = arith.addi %41, %42 : i32
//CHECK-NEXT:          scf.yield %43 : i32
//CHECK-NEXT:        }
//CHECK-NEXT:        memref.store %30, %9[] : memref<i32>
//CHECK-NEXT:        %44 = memref.load %8[] : memref<i32>
//CHECK-NEXT:        %45 = arith.index_cast %18 : index to i32
//CHECK-NEXT:        %46 = arith.addi %44, %45 : i32
//CHECK-NEXT:        scf.yield %46 : i32
//CHECK-NEXT:      }
//CHECK-NEXT:      memref.store %22, %8[] : memref<i32>
//CHECK-NEXT:      %47 = memref.load %6[] : memref<i32>
//CHECK-NEXT:      %48 = arith.addi %47, %15 : i32
//CHECK-NEXT:      %49 = arith.index_cast %48 : i32 to index
//CHECK-NEXT:      %50 = arith.addi %49, %18 : index
//CHECK-NEXT:      %51 = arith.constant 1.000000e+00 : f64
//CHECK-NEXT:      %52 = arith.constant 0 : index
//CHECK-NEXT:      %53 = arith.constant 1.000000e+01 : f64
//CHECK-NEXT:      %54 = scf.for %55 = %13 to %50 step %18 iter_args(%56 = %19) -> (i32) {
//CHECK-NEXT:        memref.store %56, %8[] : memref<i32>
//CHECK-NEXT:        %57 = arith.subi %52, %11 : index
//CHECK-NEXT:        %58 = memref.load %8[] : memref<i32>
//CHECK-NEXT:        %59 = arith.extui %58 : i32 to i64
//CHECK-NEXT:        %60 = arith.index_cast %59 : i64 to index
//CHECK-NEXT:        %61 = arith.subi %60, %11 : index
//CHECK-NEXT:        memref.store %51, %4[%61, %57] : memref<?x?xf64>
//CHECK-NEXT:        %62 = memref.load %7[] : memref<i32>
//CHECK-NEXT:        %63 = arith.addi %62, %15 : i32
//CHECK-NEXT:        %64 = arith.extui %63 : i32 to i64
//CHECK-NEXT:        %65 = arith.index_cast %64 : i64 to index
//CHECK-NEXT:        %66 = arith.subi %65, %11 : index
//CHECK-NEXT:        %67 = memref.load %8[] : memref<i32>
//CHECK-NEXT:        %68 = arith.extui %67 : i32 to i64
//CHECK-NEXT:        %69 = arith.index_cast %68 : i64 to index
//CHECK-NEXT:        %70 = arith.subi %69, %11 : index
//CHECK-NEXT:        memref.store %53, %4[%70, %66] : memref<?x?xf64>
//CHECK-NEXT:        %71 = memref.load %8[] : memref<i32>
//CHECK-NEXT:        %72 = arith.index_cast %18 : index to i32
//CHECK-NEXT:        %73 = arith.addi %71, %72 : i32
//CHECK-NEXT:        scf.yield %73 : i32
//CHECK-NEXT:      }
//CHECK-NEXT:      memref.store %54, %8[] : memref<i32>
//CHECK-NEXT:      "memref.copy"(%4, %5) : (memref<?x?xf64>, memref<?x?xf64>) -> ()
//CHECK-NEXT:      func.return
//CHECK-NEXT:    }
//CHECK-NEXT:    func.func @_QQmain() {
//CHECK-NEXT:      "memref.alloca_scope"() ({
//CHECK-NEXT:        %4 = arith.constant 512 : i32
//CHECK-NEXT:        %5 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        memref.store %4, %5[] : memref<i32>
//CHECK-NEXT:        %6 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<i32>
//CHECK-NEXT:        memref.store %4, %6[] : memref<i32>
//CHECK-NEXT:        %7 = arith.constant 1.000000e-04 : f64
//CHECK-NEXT:        %8 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<f64>
//CHECK-NEXT:        memref.store %7, %8[] : memref<f64>
//CHECK-NEXT:        func.call @_QMjacobi_modPrun_solver(%5, %6, %8) : (memref<i32>, memref<i32>, memref<f64>) -> ()
//CHECK-NEXT:        "memref.alloca_scope.return"() : () -> ()
//CHECK-NEXT:      }) : () -> ()
//CHECK-NEXT:      func.return
//CHECK-NEXT:    }
//CHECK-NEXT:    func.func private @_FortranAioBeginExternalListOutput(i32, !llvm.ptr, i32) -> !llvm.ptr 
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = !llvm.array<{{[0-9]+}} x i8>, sym_name = "_{{.*}}", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant, value = "{{.*}}", unnamed_addr = 0 : i64}> ({
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    func.func private @_FortranAioOutputAscii(!llvm.ptr, !llvm.ptr, i64) -> i1 
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = !llvm.array<17 x i8>, sym_name = "_QQclX476C6F62616C2073697A6520696E20583D", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant, value = "Global size in X=", unnamed_addr = 0 : i64}> ({
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    func.func private @_FortranAioOutputInteger32(!llvm.ptr, i32) -> i1 
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = !llvm.array<17 x i8>, sym_name = "_QQclX476C6F62616C2073697A6520696E20593D", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant, value = "Global size in Y=", unnamed_addr = 0 : i64}> ({
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    func.func private @_FortranAioEndIoStatement(!llvm.ptr) -> i32 
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = !llvm.array<10 x i8>, sym_name = "_QQclX497465726174696F6E3D", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant, value = "Iteration=", unnamed_addr = 0 : i64}> ({
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = !llvm.array<15 x i8>, sym_name = "_QQclX2052656C6174697665204E6F726D3D", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant, value = " Relative Norm=", unnamed_addr = 0 : i64}> ({
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    func.func private @_FortranAioOutputReal64(!llvm.ptr, f64) -> i1 
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = !llvm.array<14 x i8>, sym_name = "_QQclX5465726D696E61746564206F6E20", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant, value = "Terminated on ", unnamed_addr = 0 : i64}> ({
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    "llvm.mlir.global"() <{global_type = !llvm.array<27 x i8>, sym_name = "_QQclX20697465726174696F6E732C2052656C6174697665204E6F726D3D", linkage = #llvm.linkage<"internal">, addr_space = 0 : i32, constant, value = " iterations, Relative Norm=", unnamed_addr = 0 : i64}> ({
//CHECK-NEXT:    }) : () -> ()
//CHECK-NEXT:    func.func private @_FortranAProgramStart(i32, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> () 
//CHECK-NEXT:    func.func private @_FortranAProgramEndStatement() -> () 
//CHECK-NEXT:    func.func @main(%4 : i32, %5 : !llvm.ptr, %6 : !llvm.ptr) -> i32 {
//CHECK-NEXT:      %7 = memref.alloc() : memref<1xmemref<memref<1xmemref<i8>>>>
//CHECK-NEXT:      %8 = arith.constant 0 : index
//CHECK-NEXT:      %9 = memref.load %7[%8] : memref<1xmemref<memref<1xmemref<i8>>>>
//CHECK-NEXT:      %10 = "memref.extract_aligned_pointer_as_index"(%9) : (memref<memref<1xmemref<i8>>>) -> index
//CHECK-NEXT:      %11 = arith.index_cast %10 : index to i64
//CHECK-NEXT:      %12 = "llvm.inttoptr"(%11) : (i64) -> !llvm.ptr
//CHECK-NEXT:      func.call @_FortranAProgramStart(%4, %5, %6, %12) : (i32, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> ()
//CHECK-NEXT:      "memref.alloca_scope"() ({
//CHECK-NEXT:        func.call @_QQmain() : () -> ()
//CHECK-NEXT:        "memref.alloca_scope.return"() : () -> ()
//CHECK-NEXT:      }) : () -> ()
//CHECK-NEXT:      func.call @_FortranAProgramEndStatement() : () -> ()
//CHECK-NEXT:      %13 = arith.constant 0 : i32
//CHECK-NEXT:      func.return %13 : i32
//CHECK-NEXT:    }
//CHECK-NEXT:  }
//CHECK-EMPTY:  
